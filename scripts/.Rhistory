library(dplyr)
setwd(
)
getwd()
load('data/dane-zeliwo-uzupelnienie_tw.rda')
load('../data/dane-zeliwo-uzupelnienie_tw.rda')
dane
write.csv(dane,"dane-zeliwo-uzupelnienie_tw.csv")
install.packages(c("gbm", "tidyverse", "xgboost"))
install.packages("tidyverse")
install.packages('LightGBM')
library(gbm)
# install.packages('LightGBM')
#
library(gbm)
library(dplyr)
library(randomForest)
dane_<-dane[!is.na(dane$`Udział austenitu %`),]
dane_$`Wielkość sferoidów`==""
dane_[dane_==""]<-NA
setwd()
getwd()
load('../data/dane-zeliwo-uzupelnienie_tw.rda')
dane_<-dane[!is.na(dane$`Udział austenitu %`),]
dane_$`Wielkość sferoidów`==""
dane_[dane_==""]<-NA
dane_$`Nr źródła`
braki_danych<-apply(dane_, 2, function(x) sum(!is.na(x))/length(x))
dane_<-dane_[,braki_danych>0.9]
s<-sample(nrow(dane_), round(nrow(dane_)*0.2))
dane_train<-dane_[-s,]
dane_test<-dane_[s,]
srednie<-sapply(1:ncol(dane_), function(i) mean(na.omit(dane_train[,i])))
srednie
for(i in 1:ncol(dane_)){
x<-is.na(dane_[,i])
dane_[x,i]<-srednie[i]
print(i)
}
dane_train<-dane_[-s,]
dane_test<-dane_[s,]
m<-gbm(`Udział austenitu %`~., data = dane_train,
n.trees = 10000)
y_pred<-predict(m, dane_test, n.trees = 10000)
y<-dane_test$`Udział austenitu %`
mean(res^2)
res<-(y-y_pred)
res%>%density()%>%plot()
(res/y)%>%density()%>%plot()
mean(res^2)
m<-gbm(`Udział austenitu %`~., data = dane_train,
n.trees = 10000)
y_pred<-predict(m, dane_test, n.trees = 10000)
y<-dane_test$`Udział austenitu %`
res<-(y-y_pred)
res%>%density()%>%plot()
res%>%density()%>%plot()
(res/y)%>%density()%>%plot()
mean(res^2)
mean(abs((res/y))<0.1)
o<-order(-abs(res))
y[o]
y_pred[o]
m<-gbm(`Udział austenitu %`~., data = dane_,
n.trees = 10000, cv.folds = 10, bag.fraction = 0.3)
m<-gbm(`Udział austenitu %`~., data = dane_,
family = "gaussian",
bag.fraction = 0.5)
m$train.error
library(tidyverse)
library(caret)
library(xgboost)
sum(is.na(as.matrix(dane__)))
set.seed(123)
dane__<-dane_
dane__$`Nr źródła`<-NULL
names(dane__)<-  make.names(names(dane__))
model <- train(
Udział.austenitu.. ~., data = dane__, method = "xgbTree"
# ,
# trControl = trainControl("cv", number = 10)
)
# Best tuning parameter
model$bestTune
model
y_pred<-predict(model, dane_test)
predict(model,dane_test)
dane_test
predict(model,dane_test)
predict.gbm(model,dane_test)
predict(model)
predict(model,newdata = dane_test)
predict(model,newdata = dane_test[,1:((nrow(dane_test)-1))])
dane_test[,1:((nrow(dane_test)-1))]
dane_test[,1:((ncol(dane_test)-1))]
predict(model,newdata = dane_test[,1:((ncol(dane_test)-1))])
predict(model)
?train
predict(model$finalModel,newdata = dane_test)
predict(model$finalModel)
predict(model$finalModel,newdata = dane_test[,1:((ncol(dane_test)-1))])
predict(model$finalModel,newdata = as.matrix(dane_test[,1:((ncol(dane_test)-1))]))
as.matrix(dane_test[,1:((ncol(dane_test)-1))])
as.numeric(as.matrix(dane_test[,1:((ncol(dane_test)-1))]))
as.numeric(as.matrix(dane_test[,1:((ncol(dane_test)-1))]))
is.nadane_test)
is.na(dane_test)
sum(is.na(dane_test))
as.numeric(as.matrix(dane_test[,1:((ncol(dane_test)-1))]))
predict(model$finalModel,newdata =as.numeric(as.matrix(dane_test[,1:((ncol(dane_test)-1))])) )
predict(model$finalModel,newdata = xgb.Dmatrix(as.matrix(dane_test[,1:((ncol(dane_test)-1))])) )
?xgb.Dmatrix
??xgb.Dmatrix
install.packages("xgboost")
install.packages("xgboost")
install.packages("xgboost")
library("xgboost")
getwd()
load('../data/dane-zeliwo-uzupelnienie_tw.rda')
# install.packages('LightGBM')
#
library(gbm)
library(dplyr)
library(randomForest)
dane_<-dane[!is.na(dane$`Udział austenitu %`),]
dane_$`Wielkość sferoidów`==""
dane_[dane_==""]<-NA
dane_$`Nr źródła`
braki_danych<-apply(dane_, 2, function(x) sum(!is.na(x))/length(x))
dane_<-dane_[,braki_danych>0.9]
s<-sample(nrow(dane_), round(nrow(dane_)*0.2))
dane_train<-dane_[-s,]
dane_test<-dane_[s,]
srednie<-sapply(1:ncol(dane_), function(i) mean(na.omit(dane_train[,i])))
for(i in 1:ncol(dane_)){
x<-is.na(dane_[,i])
dane_[x,i]<-srednie[i]
print(i)
}
dane_train<-dane_[-s,]
dane_test<-dane_[s,]
m<-gbm(`Udział austenitu %`~., data = dane_train,
n.trees = 10000)
y_pred<-predict(m, dane_test, n.trees = 10000)
y<-dane_test$`Udział austenitu %`
res<-(y-y_pred)
res%>%density()%>%plot()
(res/y)%>%density()%>%plot()
mean(res^2)
mean(abs((res/y))<0.1)
o<-order(-abs(res))
y[o]
y_pred[o]
# Poniżej jakiś śmieciowy kod. Chcialem zrobic cross walidacje, ale nic madrego mi nie
# wyszlo. XGBoost nie chcial działać :(
m<-gbm(`Udział austenitu %`~., data = dane_,
n.trees = 10000, cv.folds = 10, bag.fraction = 0.3)
m<-gbm(`Udział austenitu %`~., data = dane_,
family = "gaussian",
bag.fraction = 0.5)
m$train.error
library(tidyverse)
library(caret)
library(xgboost)
sum(is.na(as.matrix(dane__)))
set.seed(123)
dane__<-dane_
dane__$`Nr źródła`<-NULL
names(dane__)<-  make.names(names(dane__))
model <- train(
Udział.austenitu.. ~., data = dane__, method = "xgbTree"
# ,
# trControl = trainControl("cv", number = 10)
)
# Best tuning parameter
model$bestTune
?train
dane_test
library("xgboost")
??xgb.Dmatrix
predict(model$finalModel,newdata = xgb.Dmatrix(as.matrix(dane_test[,1:((ncol(dane_test)-1))])) )
y_pred<-predict(model, dane_test)
y<-dane_test$`Udział austenitu %`
res<-(y-y_pred)
res%>%density()%>%plot()
(res/y)%>%density()%>%plot()
mean(res^2)
mean(abs((res/y))<0.1)
o<-order(-abs(res))
y[o]
y_pred[o]
predict(model$finalModel,newdata = xgb.Dmatrix(as.matrix(dane_test[,1:((ncol(dane_test)-1))])) )
predict(model$finalModel,newdata = xgb.Dmatrix(as.matrix(dane_test[,1:((ncol(dane_test)-1))])))
library(dplyr)
getwd()
dane<-read.csv('../data/dane-zeliwo.csv',
check.names=FALSE, row.names = 1)
dane<-read.csv('../data/dane-zeliwo-uzupelnienie.csv',
check.names=FALSE, row.names = 1)
tabela_twardosci<-read.csv('../data/Tabela twardosci.csv')
tabela_twardosci_HRA<-read.csv('../data/Tabela twardosci HRA.csv')
# tabela_twardosci_HRA$HRA<-as.numeric(as.character(tabela_twardosci_HRA$HRA))
tabela_twardosci_HRA2<-read.csv('../data/Tabela twardosci HRA2.csv')
names(dane)
twardosc<-dane[,c(33,34,35,36,37)]
twardosc
twardosc %>% names
twardosc$`Twardość Brinella [HB]`%>%na.omit()%>%range()
tabela_twardosci$HB%>%na.omit()%>%range()
twardosc$`Twardość Rockwella [HRC]`%>%na.omit()%>%range()
tabela_twardosci$HRC%>%na.omit()%>%range()
# Z HRA nie wiem co zrobić
twardosc$`Twardość Rockwella [HRA]`%>%na.omit()%>%range()
tabela_twardosci_HRA$HRA%>%na.omit()%>%range()
twardosc$`Twardość Rockwella [HRC]`%>%na.omit()%>%range()
tabela_twardosci$HRC%>%na.omit()%>%range()
# Z HRA nie wiem co zrobić
twardosc$`Twardość Rockwella [HRA]`%>%na.omit()%>%range()
tabela_twardosci$HRC%>%na.omit()%>%range()
twardosc$`Twardość Brinella [HB]`%>%na.omit()%>%range()
tabela_twardosci$HB%>%na.omit()%>%range()
HB<-tabela_twardosci$HB
HRB<-tabela_twardosci$HRB
HRC<-tabela_twardosci$HRC
HV<-tabela_twardosci$HV
plot(HRC, HB, type = 'l')
plot(HRB, HB, type = 'l')
plot(HV, HB, type = 'l')
HB_HRA<-c(tabela_twardosci_HRA2$HB, tabela_twardosci_HRA$HB)
HB_HRA<-c(tabela_twardosci_HRA2$HB, tabela_twardosci_HRA$HB)
HB_HRA<-(HB_HRA[!(is.na(HRA))])
HRA<-(HRA[!(is.na(HRA))])
library(dplyr)
getwd()
dane<-read.csv('../data/dane-zeliwo.csv',
check.names=FALSE, row.names = 1)
dane<-read.csv('../data/dane-zeliwo-uzupelnienie.csv',
check.names=FALSE, row.names = 1)
tabela_twardosci<-read.csv('../data/Tabela twardosci.csv')
tabela_twardosci_HRA<-read.csv('../data/Tabela twardosci HRA.csv')
# tabela_twardosci_HRA$HRA<-as.numeric(as.character(tabela_twardosci_HRA$HRA))
tabela_twardosci_HRA2<-read.csv('../data/Tabela twardosci HRA2.csv')
names(dane)
twardosc<-dane[,c(33,34,35,36,37)]
twardosc$`Twardość Brinella [HB]`%>%na.omit()%>%range()
tabela_twardosci$HB%>%na.omit()%>%range()
twardosc$`Twardość Rockwella [HRC]`%>%na.omit()%>%range()
tabela_twardosci$HRC%>%na.omit()%>%range()
# Z HRA nie wiem co zrobić
twardosc$`Twardość Rockwella [HRA]`%>%na.omit()%>%range()
tabela_twardosci_HRA$HRA%>%na.omit()%>%range()
twardosc$`Twardość Rockwella [HRA]`%>%na.omit()%>%sort()
# twardosc$`Twardość Rockwella [HRB]`%>%na.omit()%>%range() same braki danych
twardosc$`Twardość Vickersa [HV]`%>%na.omit()%>%range()
tabela_twardosci$HV%>%na.omit()%>%range()
HB<-tabela_twardosci$HB
HRB<-tabela_twardosci$HRB
HRC<-tabela_twardosci$HRC
HV<-tabela_twardosci$HV
plot(HRC, HB, type = 'l')
plot(HRB, HB, type = 'l')
plot(HV, HB, type = 'l')
# W HRA dane z tabeli wykraczały poza zakres.
# Użyłem danych z tabeli i dodatkowo wkleiłem do kalkulatora kilka punktów z danych.
HRA<-c(tabela_twardosci_HRA2$HRA, tabela_twardosci_HRA$HRA)
HB_HRA<-c(tabela_twardosci_HRA2$HB, tabela_twardosci_HRA$HB)
HB_HRA<-(HB_HRA[!(is.na(HRA))])
HRA<-(HRA[!(is.na(HRA))])
HB_HRA<-HB_HRA[order(HRA)]
HRA<-sort(HRA)
plot(HRA, HB_HRA, type = 'l')
HRA_f<-splinefun(HRA, HB_HRA)
plot(HRA, HB_HRA, type = 'l')
lines(HRA, HRA_f(HRA), type='l', col = 'red')
HRC_f<-splinefun(HRC, HB)
plot(HRC, HB, type = 'l')
lines(HRC, HRC_f(HRC), type='l', col = 'red')
HRB_f<-splinefun(HRB, HB)
plot(HRB, HB, type = 'l')
lines(HRB, HRB_f(HRB), type='l', col = 'red')
HV_f<-splinefun(HV, HB)
plot(HV, HB, type = 'l')
lines(HV, HV_f(HV), type='l', col = 'red')
HRA_f(dane$`Twardość Rockwella [HRA]`)
HRB_f(dane$`Twardość Rockwella [HRB]`)
HRC_f(dane$`Twardość Rockwella [HRC]`)
HV_f(dane$`Twardość Vickersa [HV]`)
dane$`Twardość Brinella [HB]`<-round(coalesce(
dane$`Twardość Brinella [HB]`,
HRA_f(dane$`Twardość Rockwella [HRA]`),
HRB_f(dane$`Twardość Rockwella [HRB]`),
HRC_f(dane$`Twardość Rockwella [HRC]`),
HV_f(dane$`Twardość Vickersa [HV]`)
), 2)
x<-dane$`Twardość Brinella [HB]`
is.na(x)%>%sum()/length(x)
# Potrzebowałem na potrzeby pliku wola911 twardości w skali Vickerse'a
HV_f_odwrotna<-splinefun(HB, HV)
dane$`Twardość Vickersa [HV]`<-coalesce(dane$`Twardość Vickersa [HV]`, HV_f_odwrotna(dane$`Twardość Brinella [HB]`))
# Pozostałe braki danych wynikają z braku jakiejkolwiek twardości
all(is.na(twardosc[is.na(x),]))
save(dane, file='./Github/metal/data/dane-zeliwo-uzupelnienie_tw.rda')
load('./Github/metal/data/dane-zeliwo-uzupelnienie_tw.rda')
# write.csv(dane,"./Github/metal/data/dane-zeliwo-uzupelnienie_tw.csv")
library(dplyr)
getwd()
dane<-read.csv('../data/dane-zeliwo.csv',
check.names=FALSE, row.names = 1)
dane<-read.csv('../data/dane-zeliwo-uzupelnienie.csv',
check.names=FALSE, row.names = 1)
tabela_twardosci<-read.csv('../data/Tabela twardosci.csv')
tabela_twardosci_HRA<-read.csv('../data/Tabela twardosci HRA.csv')
# tabela_twardosci_HRA$HRA<-as.numeric(as.character(tabela_twardosci_HRA$HRA))
tabela_twardosci_HRA2<-read.csv('../data/Tabela twardosci HRA2.csv')
names(dane)
twardosc<-dane[,c(33,34,35,36,37)]
twardosc$`Twardość Brinella [HB]`%>%na.omit()%>%range()
tabela_twardosci$HB%>%na.omit()%>%range()
twardosc$`Twardość Rockwella [HRC]`%>%na.omit()%>%range()
tabela_twardosci$HRC%>%na.omit()%>%range()
# Z HRA nie wiem co zrobić
twardosc$`Twardość Rockwella [HRA]`%>%na.omit()%>%range()
tabela_twardosci_HRA$HRA%>%na.omit()%>%range()
twardosc$`Twardość Rockwella [HRA]`%>%na.omit()%>%sort()
twardosc$`Twardość Vickersa [HV]`%>%na.omit()%>%range()
tabela_twardosci$HV%>%na.omit()%>%range()
HB<-tabela_twardosci$HB
HRB<-tabela_twardosci$HRB
HRC<-tabela_twardosci$HRC
HV<-tabela_twardosci$HV
plot(HRC, HB, type = 'l')
plot(HRB, HB, type = 'l')
plot(HV, HB, type = 'l')
# W HRA dane z tabeli wykraczały poza zakres.
# Użyłem danych z tabeli i dodatkowo wkleiłem do kalkulatora kilka punktów z danych.
HRA<-c(tabela_twardosci_HRA2$HRA, tabela_twardosci_HRA$HRA)
HB_HRA<-c(tabela_twardosci_HRA2$HB, tabela_twardosci_HRA$HB)
HB_HRA<-(HB_HRA[!(is.na(HRA))])
HRA<-(HRA[!(is.na(HRA))])
HB_HRA<-HB_HRA[order(HRA)]
HRA<-sort(HRA)
plot(HRA, HB_HRA, type = 'l')
HRA_f<-splinefun(HRA, HB_HRA)
plot(HRA, HB_HRA, type = 'l')
lines(HRA, HRA_f(HRA), type='l', col = 'red')
HRC_f<-splinefun(HRC, HB)
plot(HRC, HB, type = 'l')
lines(HRC, HRC_f(HRC), type='l', col = 'red')
HRB_f<-splinefun(HRB, HB)
plot(HRB, HB, type = 'l')
lines(HRB, HRB_f(HRB), type='l', col = 'red')
HV_f<-splinefun(HV, HB)
plot(HV, HB, type = 'l')
lines(HV, HV_f(HV), type='l', col = 'red')
HRA_f(dane$`Twardość Rockwella [HRA]`)
HRB_f(dane$`Twardość Rockwella [HRB]`)
HRC_f(dane$`Twardość Rockwella [HRC]`)
HV_f(dane$`Twardość Vickersa [HV]`)
dane$`Twardość Brinella [HB]`<-round(coalesce(
dane$`Twardość Brinella [HB]`,
HRA_f(dane$`Twardość Rockwella [HRA]`),
HRB_f(dane$`Twardość Rockwella [HRB]`),
HRC_f(dane$`Twardość Rockwella [HRC]`),
HV_f(dane$`Twardość Vickersa [HV]`)
), 2)
x<-dane$`Twardość Brinella [HB]`
is.na(x)%>%sum()/length(x)
HV_f_odwrotna<-splinefun(HB, HV)
dane$`Twardość Vickersa [HV]`<-coalesce(dane$`Twardość Vickersa [HV]`, HV_f_odwrotna(dane$`Twardość Brinella [HB]`))
# Pozostałe braki danych wynikają z braku jakiejkolwiek twardości
all(is.na(twardosc[is.na(x),]))
library(gbm)
library(dplyr)
library(randomForest)
load('./Github/metal/data/dane-zeliwo-uzupelnienie_tw.rda')
dane$`Twardość Rockwella [HRC]`<-NULL
dane$`Twardość Rockwella [HRA]`<-NULL
load('../data/dane-zeliwo-uzupelnienie_tw.rda')
dane$`Twardość Rockwella [HRC]`<-NULL
dane$`Twardość Rockwella [HRA]`<-NULL
dane$`Twardość Rockwella [HRB]`<-NULL
dane$`Twardość Vickersa [HV]`<-NULL
dane_<-dane[!is.na(dane$`Udarność Charpy [J]`),]
dane_[dane_==""]<-NA
braki_danych<-apply(dane_, 2, function(x) sum(!is.na(x))/length(x))
sort(braki_danych)
# Jeżeli jakość zmiennej będzie powyżej progu q, to imputuje zmienną średnią.
# Jeżeli poniżej, to dzielę zmienna według kwantyli i wprowadzam jako factor
# + dodatkowy poziom na braki
q<-0.9
z<-names(dane_[,braki_danych<=q])
for(i in seq_along(z)){
x<-dane_[[z[i]]]
if(!is.numeric(x)) next
# k<-1 + 3.322*log(length(na.omit(x))) # liczba klas według zasady kciuka dla histogramów
k<-3
klasy<-seq(0, 1, by = 1/k)
new<-cut(x, unique(quantile(x, klasy, na.rm = TRUE)))
levels(new)<-c(levels(new), "Inne")
new[is.na(new)]<-"Inne"
dane_[[z[i]]]<-new
}
# Produkuje zmienne 0-1 mówiące czy zmienna była uzupełniona brakiem
z<-names(braki_danych)[braki_danych<1]
for(i in seq_along(z)){
zz<-paste0(z[i], "_is_na")
dane_[[zz]]<-is.na(dane_[[z[i]]])
}
braki_danych<-apply(dane_, 2, function(x) sum(!is.na(x))/length(x))
dane_<-dane_[,braki_danych>q]
s<-sample(nrow(dane_), round(nrow(dane_)*0.2))
dane_train<-dane_[-s,]
dane_test<-dane_[s,]
srednie<-sapply(1:ncol(dane_), function(i) mean(na.omit(dane_train[,i])))
for(i in 1:ncol(dane_)){
x<-is.na(dane_[,i])
dane_[x,i]<-srednie[i]
}
braki_danych<-apply(dane_, 2, function(x) sum(!is.na(x))/length(x))
dane_<-dane_[,braki_danych>q]
dane_train<-dane_[-s,]
dane_test<-dane_[s,]
dane_train<-dane_[-s,]
dane_test<-dane_[s,]
m<-gbm(`Udarność Charpy [J]`~., data = dane_train,
n.trees = 50000)
y<-dane_test$`Udarność Charpy [J]`
l<-seq(0, 5000, by = 100)
mse<-vector()
for(i in seq_along(l)){
mse[i]<-mean((y-predict(m, dane_test, n.trees = l[i]))^2)
}
plot(l, mse, type='l')
y<-dane_test$`Udarność Charpy [J]`
y_pred<-predict(m, dane_test, n.trees = 4000)
res<-(y-y_pred)
mean(res^2)
res%>%density()%>%plot()
res
m<-gbm(`Udarność Charpy [J]`~., data = dane_train,
n.trees = 50000)
dane_train
s<-sample(nrow(dane_), round(nrow(dane_)*0.2))
dane_train<-dane_[-s,]
dane_test<-dane_[s,]
dane_train<-dane_[-s,]
dane_test<-dane_[s,]
m<-gbm(`Udarność Charpy [J]`~., data = dane_train,
n.trees = 50000)
